geom_boxplot(alpha = 0.7, outlier.shape = 16, outlier.color = "blue", outlier.size = 2) +
# Marker gennemsnittet med en rød prik
stat_summary(fun = mean, geom = "point", color = "darkred", size = 3, shape = 18) +
# Tilføj tekst med gennemsnitlig mødelængde for hver gruppe
geom_text(data = meeting_churn_stats, aes(x = churn, y = gennemsnit,
label = paste0("Gns: ", gennemsnit, " min")),
color = "darkred", size = 4, nudge_y = 5, inherit.aes = FALSE) +
# Vis antal observationer som tekst over hver boks
geom_text(data = meeting_churn_stats, aes(x = churn, y = max(featured$MeetingLength, na.rm = TRUE) + 5,
label = paste0("n = ", n)),
color = "black", size = 4, inherit.aes = FALSE) +
# Vend akserne, så medlemsstatus vises lodret
coord_flip() +
# Brug farver der skelner aktiv og stoppet medlemsstatus
scale_fill_manual(values = c("Aktiv" = "darkgreen", "Stoppet" = "darkred")) +
# Tilføj titler og aksetekster
labs(
title = "Mødelængde vs. medlemsstatus",
subtitle = "Rød prik = gennemsnit • Blå prikker = outliers",
x = "Medlemsstatus",
y = "Mødelængde (minutter)",
fill = "Status"
) +
# Brug minimalistisk tema og fjern legend
theme_minimal(base_size = 13) +
theme(legend.position = "none")
ggsave("images/EDA_13_mødelængde_medlemsstatus.png", width = 7, height = 4, dpi = 300)
# ------------------------------------------------------------------------------
# 5.14 Histogram: Fordeling af mødelængder
# ------------------------------------------------------------------------------
# Vi undersøger hvordan mødelængder fordeler sig blandt aktive medlemmer,
# for at se om der er typiske længder, outliers eller skævhed.
featured |>
filter(churn == 0, !is.na(MeetingLength), MeetingLength > 0) |>
ggplot(aes(x = MeetingLength)) +
geom_histogram(binwidth = 10, fill = "darkgreen", color = "white", boundary = 0) +
labs(
title = "Fordeling af mødelængder (aktive medlemmer)",
subtitle = "Histogram med binwidth = 10 minutter",
x = "Mødelængde (minutter)",
y = "Antal møder"
) +
theme_minimal()
ggsave("images/EDA_14_fordeling_mødelængder.png", width = 7, height = 4, dpi = 300)
# ------------------------------------------------------------------------------
# 5.15 Korrellationsmatrix: Numeriske variable
# ------------------------------------------------------------------------------
# Vi ønsker at undersøge, hvordan de numeriske variable i datasættet hænger sammen.
# Det gør vi ved at udtrække alle numeriske kolonner og beregne en korrelationsmatrix.
# Denne visualiseres som et cirkelplot med Pearson-korrelationer.
# Udtræk kun de kolonner i datasættet, der er numeriske
featured_numerisk <- featured |>
select(where(is.numeric)) |>
# Fjern rækker med NA-værdier, da korrelationsberegning kræver komplette værdier
drop_na()
# Beregn korrelationsmatrix ved hjælp af Pearson's metode
cor_matrix <- cor(featured_numerisk, use = "pairwise.complete.obs")
# Afrund korrelationerne til 2 decimaler for pænere visning (valgfrit trin)
cor_matrix_rounded <- round(cor_matrix, 2)
# Visualisér korrelationerne med et "cirkelplot" fra pakken 'corrplot'
corrplot::corrplot(
cor_matrix,
method = "circle",       # Brug cirkler til at vise styrke og retning af korrelation
type = "lower",          # Vis kun nederste trekant (mere overskueligt)
# Tekst og talindstillinger
tl.cex = 0.8,            # Størrelse på tekstetiketter (variabelnavne)
tl.col = "black",        # Farve på variabelnavne
addCoef.col = "darkgreen"    # Vis selve korrelationstallet inde i cirklerne
)
ggsave("images/EDA_15_korrellationsmatrix.png", width = 7, height = 4, dpi = 300)
# Chunk 7
# ------------------------------------------------------------------------------
# 6. Preprocessing
# ------------------------------------------------------------------------------
set.seed(2025)
churn_split <- initial_split(feature_engineering, prop = 0.8, strata = churn)
churn_train <- training(churn_split)
churn_test  <- testing(churn_split)
churn_folds <- vfold_cv(churn_train, v = 10, strata = churn)
churn_recipe <-
recipe(churn ~ ., data = churn_train) |>
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_numeric_predictors()) |>
step_downsample(churn)  # Brug evt. step_smote(churn) hvis ekstrem ubalance
# Chunk 8
# ------------------------------------------------------------------------------
# 7. Modelling
# ------------------------------------------------------------------------------
# Model specs
rf_spec <- rand_forest(mtry = tune(), min_n = tune()) |>
set_engine("ranger", importance = "impurity") |>
set_mode("classification")
xgb_spec <- boost_tree(trees = tune(), mtry = tune(), learn_rate = tune()) |>
set_engine("xgboost") |>
set_mode("classification")
log_reg_spec <- logistic_reg(penalty = tune(), mixture = tune()) |>
set_engine("glmnet") |>
set_mode("classification")
knn_spec <- nearest_neighbor(neighbors = tune(), weight_func = tune()) |>
set_engine("kknn") |>
set_mode("classification")
nb_spec <- naive_Bayes(smoothness = tune(), Laplace = tune()) |>
set_engine("naivebayes") |>
set_mode("classification")
svm_spec <- svm_rbf(cost = tune(), rbf_sigma = tune()) |>
set_engine("kernlab") |>
set_mode("classification")
# Samlet workflow set
churn_workflow_set <- workflow_set(
preproc = list(churn_recipe = churn_recipe),
models = list(
rf = rf_spec,
xgboost = xgb_spec,
logistic = log_reg_spec,
knn = knn_spec,
naive_bayes = nb_spec,
svm_rbf = svm_spec
)
)
# Chunk 9
# ------------------------------------------------------------------------------
# 8. Evaluate metrics
# ------------------------------------------------------------------------------
churn_metrics <- metric_set(accuracy, roc_auc, f_meas, sens, spec)
grid_ctrl <- control_grid(
verbose = TRUE,
save_pred = TRUE,
parallel_over = "everything",
save_workflow = TRUE
)
plan(multisession)
strt.time <- Sys.time()
# Chunk 10
# Vi kører modellerne - den står og arbejder
churn_results <- churn_workflow_set |>
workflow_map(
resamples = churn_folds,
grid = 5,
metrics = churn_metrics,
control = grid_ctrl,
seed = 2025
)
# Chunk 11
Sys.time() - strt.time
plan(sequential)
# Sammenlign resultater
churn_results |>
rank_results(select_best = TRUE) |>
select(wflow_id, .metric, mean) |>
pivot_wider(names_from = .metric, values_from = mean) |>
arrange(-f_meas)
autoplot(churn_results, select_best = TRUE)
# Chunk 12
# ------------------------------------------------------------------------------
# 9. Visualiseringer
# -------------------------------------------------------------------------
# Plot modeller efter deres performance
# -------------------------------------------------------------------------
# Din tibble, hvis ikke du allerede har den i en variabel:
metrics_df <- tibble::tibble(
wflow_id = c("churn_recipe_rf", "churn_recipe_xgboost", "churn_recipe_svm_rbf",
"churn_recipe_logistic", "churn_recipe_knn", "churn_recipe_naive_bayes"),
accuracy = c(0.825, 0.827, 0.845, 0.807, 0.743, 0.710),
f_meas   = c(0.724, 0.723, 0.708, 0.697, 0.592, 0.287),
roc_auc  = c(0.877, 0.881, 0.439, 0.858, 0.778, 0.855),
sens     = c(0.777, 0.766, 0.643, 0.755, 0.634, 0.272),
spec     = c(0.845, 0.852, 0.929, 0.828, 0.788, 0.893)
)
# Pivot til langt format
metrics_long <- metrics_df %>%
pivot_longer(cols = -wflow_id, names_to = "metric", values_to = "score")
# Gør labels lidt pænere
metrics_focus <- metrics_long %>%
filter(metric %in% c("accuracy", "f_meas", "roc_auc")) %>%
mutate(metric = case_when(
metric == "accuracy" ~ "Accuracy",
metric == "f_meas" ~ "F1-score",
metric == "roc_auc" ~ "ROC AUC",
TRUE ~ metric
))
# Nr. 1: BarPlot med værdier for denne 3 metrikker
ggplot(metrics_focus, aes(x = metric, y = score, fill = metric)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = round(score, 2)), vjust = -0.3, size = 3.5) +
facet_wrap(~ wflow_id) +
ylim(0, 1.05) +
labs(
title = "Model performance (Accuracy, F1 og ROC AUC)",
x = NULL,
y = "Score"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 0),
plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
) +
scale_fill_brewer(palette = "Set3")
ggsave("images/1_model_performance.png", width = 7, height = 4, dpi = 300)
# Nr. 2: Linje plot
ggplot(metrics_focus, aes(x = wflow_id, y = score, color = metric, group = metric)) +
geom_line(size = 1) +
geom_point(size = 3) +
geom_text(aes(label = round(score, 2)), vjust = -0.7, size = 3) +
scale_color_brewer(palette = "Dark2") +
labs(
title = "Sammenligning på tværs af modeller",
x = "Model",
y = "Score"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)
)
ggsave("images/2_linje_plot.png", width = 7, height = 4, dpi = 300)
# Nr. 3: Heatmap pr. model og metrik
ggplot(metrics_focus, aes(x = metric, y = wflow_id, fill = score)) +
geom_tile(color = "white") +
geom_text(aes(label = round(score, 2)), size = 3) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(
title = "Performance heatmap pr. model og metrik",
x = "Metric",
y = "Model"
) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
ggsave("images/3_heatmap_pr_model.png", width = 7, height = 4, dpi = 300)
# -------------------------------------------------------------------------
# Plot for xgboost og Random forest med de vigtigste variabler
# -------------------------------------------------------------------------
# Hent tuning-resultater for rf og xgboost
rf_result <- churn_results %>% extract_workflow_set_result("churn_recipe_rf")
xgb_result <- churn_results %>% extract_workflow_set_result("churn_recipe_xgboost")
# Hent workflow (før det er fit)
rf_workflow <- churn_results %>% extract_workflow("churn_recipe_rf")
xgb_workflow <- churn_results %>% extract_workflow("churn_recipe_xgboost")
# Vælg bedste parametre og fit modellen
best_rf <- rf_workflow %>%
finalize_workflow(select_best(rf_result, metric = "f_meas")) %>%
fit(data = churn_train)
best_xgb <- xgb_workflow %>%
finalize_workflow(select_best(xgb_result, metric = "f_meas")) %>%
fit(data = churn_train)
# Feature importance
vip_rf <- vi(extract_fit_parsnip(best_rf)) %>% mutate(model = "Random Forest")
vip_xgb <- vi(extract_fit_parsnip(best_xgb)) %>% mutate(model = "XGBoost")
# Kombinér og vis kun top 10 vigtigste variabler pr. model
vip_combined <- bind_rows(vip_rf, vip_xgb) %>%
group_by(model) %>%
slice_max(order_by = Importance, n = 10) %>%
ungroup() %>%
mutate(Variable = str_wrap(Variable, width = 25))
# Plot med labels og tekstrotation optimeret
ggplot(vip_combined, aes(x = reorder(Variable, Importance), y = Importance, fill = model)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = round(Importance, 2)), hjust = -0.1, size = 3) +
facet_wrap(~ model, scales = "free") +
coord_flip() +
labs(
title = "Top 10 vigtigste variabler pr. model",
x = "Variabel",
y = "Vigtighed"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
strip.text = element_text(size = 12, face = "bold"),
axis.text.y = element_text(size = 9)
) +
scale_y_continuous(expand = expansion(mult = c(0, 0.10))) #ektra space til labels
ggsave("images/4_top_10_variabler_pr_model.png", width = 7, height = 4, dpi = 300)
# ------------------------------------------------------------------------------
# Chunk 13
# -------------------------------------------------------
# 10. Endelig model – Finetuning af Random Forest
# -------------------------------------------------------
# undersøg kun på hele datasæt
# 1. Lav et workflow set med kun én model: Random Forest
churn_workflow_set_rf <- workflow_set(
preproc = list(churn_recipe = churn_recipe),
models  = list(rf = rf_spec)  # kun én model
)
# 2. Tænd for parallelisering
plan(multisession)
# 3. Start tidstagning
strt.time <- Sys.time()
# Chunk 14
# 4. Tuning af kun Random Forest med 25 kombinationer
churn_results_rf <- churn_workflow_set_rf |>  # <-- her var der fejl i dit input
workflow_map(
resamples = churn_folds,
grid = 25,
metrics = churn_metrics,
control = grid_ctrl,
seed = 2025
)
# Chunk 15
# 5. Tid brugt
Sys.time() - strt.time
# 6. Sluk for parallelisering
plan(sequential)
# 7. Vis bedste resultater pr. metrik
churn_results_rf |>
rank_results(select_best = TRUE) |>
select(wflow_id, .metric, mean) |>
pivot_wider(names_from = .metric, values_from = mean) |>
arrange(-f_meas)
# 8. Visualisér den bedste model
autoplot(churn_results_rf, select_best = TRUE)
# Chunk 16
# ------------------------------------------------------------------------------
# 11. Evaluering af bedste model på testdatasættet (Random Forest)
# ------------------------------------------------------------------------------
# Bemærk: Modellen i dette afsnit er baseret på finetuning med 25 kombinationer
# 1. Find bedste parametre for den bedste model
best_results <- churn_results_rf |>
extract_workflow_set_result("churn_recipe_rf") |>
select_best(metric = "f_meas")
# 2. Finaliser workflow med de fundne parametre
final_wf <- churn_results_rf |>
extract_workflow("churn_recipe_rf") |>
finalize_workflow(best_results)
# 3. Træn modellen på træningsdata og evaluer på testdata
churn_last_fit <- final_wf |>
last_fit(split = churn_split, metrics = churn_metrics)
# 4. Udskriv evalueringsmetrikker
collect_metrics(churn_last_fit)
# 5. Gem confusion matrix som objekt (brugbar til præsentation)
conf_matrix <- churn_last_fit |>
collect_predictions() |>
conf_mat(estimate = .pred_class, truth = churn)
# 6. Gem test-prædiktioner hvis ønsket
test_preds <- collect_predictions(churn_last_fit)
# 7. Træn endelig model på hele datasættet
final_model <- fit(final_wf, data = feature_engineering)
# 8. Gem modellen
saveRDS(final_model, "final_churn_model.rds")
# ------------------------------------------------------------------------------
# 11.1 Eksempel: Forudsig churn for én ny virksomhed
# ------------------------------------------------------------------------------
new_company <- tibble(
Employees = 15,
PostalCode = factor("8800"),
CompanyTypeName = factor("Aktieselskab"),
har_haft_kontakt = factor("Ja"),
deltaget_i_event = factor("Nej"),
hjælp_kategori = factor("Strategi Udvikling"),
medlem_antal_år = 2,
Branche_navn = factor("Fremstilling af maskiner og udstyr i.a.n."),
MeetingLength = 180,
PNumber = 12345678
)
# Forudsiger klassifikation og sandsynlighed
predict(final_model, new_company)                    # 0 = bliver, 1 = churn
predict(final_model, new_company, type = "prob")     # churn-sandsynlighed
# ------------------------------------------------------------------------------
# 11.2 Forudsig churn for ALLE virksomheder og tilføj resultater
# ------------------------------------------------------------------------------
# Modellen anvendes nu på hele medlemsdatabasen for at identificere churn-risiko
# Forudsiger sandsynlighed og klasse
churn_probs   <- predict(final_model, feature_engineering, type = "prob")
churn_classes <- predict(final_model, feature_engineering)
# Kombiner og omdøb kolonner
all_predictions <- bind_cols(churn_probs, churn_classes) |>
rename(
churn_prob = .pred_1,      # Sandsynlighed for churn
churn_class = .pred_class  # Klassifikation (0/1)
)
# Tilføj til datasættet og konvertér sandsynlighed til procent
full_results <- feature_engineering |>
bind_cols(all_predictions) |>
mutate(
churn_prob = round(churn_prob * 100, 1)
)
# Tilføj churn-risikokategorier tidligt (bruges i visualiseringer og rapporter)
full_results <- full_results |>
mutate(
churn_risiko = case_when(
churn_prob >= 80 ~ "Høj risiko",
churn_prob >= 60 ~ "Moderat risiko",
churn_prob >= 40 ~ "Lav risiko",
TRUE             ~ "Minimal risiko"
)
)
# ------------------------------------------------------------------------------
# 11.3 Visualisering: Fordeling af churn-risikokategorier (kun aktive medlemmer)
# ------------------------------------------------------------------------------
full_results |>
filter(churn == 0) |>
count(churn_risiko) |>
ggplot(aes(x = reorder(churn_risiko, -n), y = n, fill = churn_risiko)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = n), vjust = -1, size = 5) +
scale_fill_manual(values = c(
"Minimal risiko" = "darkgreen",
"Lav risiko"     = "green4",
"Moderat risiko" = "orange",
"Høj risiko"     = "darkred"
)) +
scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
coord_cartesian(clip = "off") +
labs(
title = "Fordeling af churn-risiko blandt aktive medlemmer",
subtitle = "Kategorier: Minimal (<40%), Lav (40–59.9%), Moderat (60–79.9%), Høj (80–100%)",
x = "Risikokategori",
y = "Antal virksomheder"
) +
theme_minimal()
ggsave("images/9_churn_risikokategorier_aktive.png", width = 7, height = 4, dpi = 300)
# ------------------------------------------------------------------------------
# 11.4 Churn-risiko: Filtrér medlemmer (churn == 0) med høj risiko (churn_class == 1)
# ------------------------------------------------------------------------------
top_risiko_medlemmer <- full_results |>
filter(churn == 0, churn_class == 1) |>
arrange(desc(churn_prob)) |>
slice_head(n = 20)  # Call to action: top 20
# ------------------------------------------------------------------------------
# 11.5 Visualiseringer: Brancher og postnumre med høj churn
# ------------------------------------------------------------------------------
# Brancher med højest gennemsnitlig churn
full_results |>
group_by(Branche_navn) |>
summarise(gennemsnitlig_churn = mean(churn_prob), n = n()) |>
arrange(desc(gennemsnitlig_churn)) |>
slice_head(n = 5) |>
ggplot(aes(x = reorder(Branche_navn, gennemsnitlig_churn), y = gennemsnitlig_churn)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 5 churn-risiko", x = "Branche", y = "Gns. churn sandsynlighed (%)") +
theme_minimal()
ggsave("images/5_brancher_højeste_churn.png", width = 7, height = 4, dpi = 300)
# Postnumre med højest gennemsnitlig churn
full_results |>
group_by(PostalCode) |>
summarise(gennemsnitlig_churn = mean(churn_prob), n = n()) |>
arrange(desc(gennemsnitlig_churn)) |>
slice_head(n = 5) |>
ggplot(aes(x = reorder(as.character(PostalCode), gennemsnitlig_churn), y = gennemsnitlig_churn)) +
geom_col(fill = "darkred") +
coord_flip() +
labs(title = "Top 5 postnumre med højest churn-risiko", x = "Postnummer", y = "Gns. churn sandsynlighed (%)") +
theme_minimal()
ggsave("images/6_postnummer_højeste_churn.png", width = 7, height = 4, dpi = 300)
# ------------------------------------------------------------------------------
# 11.6 Hvad kendetegner virksomheder der IKKE churner?
# ------------------------------------------------------------------------------
full_results |>
filter(churn_class == 0) |>  # Virksomheder som modellen forudser bliver
count(Branche_navn, sort = TRUE) |>
slice_head(n = 5) |>
ggplot(aes(x = reorder(Branche_navn, n), y = n)) +
geom_col(fill = "forestgreen") +
coord_flip() +
labs(
title = "Top 5 der ikke churner",
x = "Branche",
y = "Antal virksomheder"
) +
theme_minimal()
ggsave("images/7_top5_der_ikke_churner.png", width = 7, height = 4, dpi = 300)
# Sammenlignende statistik på udvalgte variabler
# churn_class:
# 0 = modellen tror de bliver
# 1 = modellen tror de churner
full_results |>
group_by(churn_class) |>
summarise(
mødelængde = mean(MeetingLength),
medlem_år = mean(medlem_antal_år),
kontakt_rate = mean(har_haft_kontakt == "Ja"),
event_rate = mean(deltaget_i_event == "Ja")
)
# ------------------------------------------------------------------------------
# 11.7 Hvad er de vigtigste parametre
# ------------------------------------------------------------------------------
# 1. Udtræk tuning-resultater og workflow
rf_result <- churn_results_rf |> extract_workflow_set_result("churn_recipe_rf")
rf_workflow <- churn_results_rf |> extract_workflow("churn_recipe_rf")
# 2. Find bedste parametre og træn modellen på træningsdata
best_rf <- rf_workflow |>
finalize_workflow(select_best(rf_result, metric = "f_meas")) |>
fit(data = churn_train)
# 3. Brug vip til at finde top 10 vigtigste variabler
vip_rf <- vi(extract_fit_parsnip(best_rf)) |>
slice_max(order_by = Importance, n = 10) |>
mutate(Variable = str_wrap(Variable, width = 30))
# 4. Plot
ggplot(vip_rf, aes(x = reorder(Variable, Importance), y = Importance)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(
title = "Top 10 variabler (RF)",
x = "Variabel",
y = "Vigtighed"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.text.y = element_text(size = 10)
)
# 5. Gem billedet
ggsave("images/8_top_10_variabler_rf.png", width = 7, height = 4, dpi = 300)
# Gemmer full_results som RDS
saveRDS(full_results, "full_results.rds")
top_risiko_medlemmer <- full_results |>
filter(churn == 0, churn_class == 1) |>
arrange(desc(churn_prob)) |>
slice_head(n = 20)  # Call to action: top 20
View(top_risiko_medlemmer)
