set_mode("classification")
log_reg_spec <- logistic_reg(penalty = tune(), mixture = tune()) |>
set_engine("glmnet") |>
set_mode("classification")
knn_spec <- nearest_neighbor(neighbors = tune(), weight_func = tune()) |>
set_engine("kknn") |>
set_mode("classification")
nb_spec <- naive_Bayes(smoothness = tune(), Laplace = tune()) |>
set_engine("naivebayes") |>
set_mode("classification")
svm_spec <- svm_rbf(cost = tune(), rbf_sigma = tune()) |>
set_engine("kernlab") |>
set_mode("classification")
# Samlet workflow set
churn_workflow_set <- workflow_set(
preproc = list(churn_recipe = churn_recipe),
models = list(
rf = rf_spec,
xgboost = xgb_spec,
logistic = log_reg_spec,
knn = knn_spec,
naive_bayes = nb_spec,
svm_rbf = svm_spec
)
)
# Chunk 9
# ------------------------------------------------------------------------------
# 8. Evaluate metrics
# ------------------------------------------------------------------------------
churn_metrics <- metric_set(accuracy, roc_auc, f_meas, sens, spec)
grid_ctrl <- control_grid(
verbose = TRUE,
save_pred = TRUE,
parallel_over = "everything",
save_workflow = TRUE
)
plan(multisession)
strt.time <- Sys.time()
# Chunk 10
# Vi kører modellerne - den står og arbejder
churn_results <- churn_workflow_set |>
workflow_map(
resamples = churn_folds,
grid = 5,
metrics = churn_metrics,
control = grid_ctrl,
seed = 2025
)
# Chunk 11
Sys.time() - strt.time
plan(sequential)
# Sammenlign resultater
churn_results |>
rank_results(select_best = TRUE) |>
select(wflow_id, .metric, mean) |>
pivot_wider(names_from = .metric, values_from = mean) |>
arrange(-f_meas)
autoplot(churn_results, select_best = TRUE)
# Chunk 12
# ------------------------------------------------------------------------------
# 9. Visualiseringer
# -------------------------------------------------------------------------
# Plot modeller efter deres performance
# -------------------------------------------------------------------------
# Din tibble, hvis ikke du allerede har den i en variabel:
metrics_df <- tibble::tibble(
wflow_id = c("churn_recipe_rf", "churn_recipe_xgboost", "churn_recipe_svm_rbf",
"churn_recipe_logistic", "churn_recipe_knn", "churn_recipe_naive_bayes"),
accuracy = c(0.825, 0.827, 0.845, 0.807, 0.743, 0.710),
f_meas   = c(0.724, 0.723, 0.708, 0.697, 0.592, 0.287),
roc_auc  = c(0.877, 0.881, 0.439, 0.858, 0.778, 0.855),
sens     = c(0.777, 0.766, 0.643, 0.755, 0.634, 0.272),
spec     = c(0.845, 0.852, 0.929, 0.828, 0.788, 0.893)
)
# Pivot til langt format
metrics_long <- metrics_df %>%
pivot_longer(cols = -wflow_id, names_to = "metric", values_to = "score")
# Gør labels lidt pænere
metrics_focus <- metrics_long %>%
filter(metric %in% c("accuracy", "f_meas", "roc_auc")) %>%
mutate(metric = case_when(
metric == "accuracy" ~ "Accuracy",
metric == "f_meas" ~ "F1-score",
metric == "roc_auc" ~ "ROC AUC",
TRUE ~ metric
))
# Nr. 1: BarPlot med værdier for denne 3 metrikker
ggplot(metrics_focus, aes(x = metric, y = score, fill = metric)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = round(score, 2)), vjust = -0.3, size = 3.5) +
facet_wrap(~ wflow_id) +
ylim(0, 1.05) +
labs(
title = "Model performance (Accuracy, F1 og ROC AUC)",
x = NULL,
y = "Score"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 0),
plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
) +
scale_fill_brewer(palette = "Set3")
ggsave("images/1_model_performance.png", width = 7, height = 4, dpi = 300)
# Nr. 2: Linje plot
ggplot(metrics_focus, aes(x = wflow_id, y = score, color = metric, group = metric)) +
geom_line(size = 1) +
geom_point(size = 3) +
geom_text(aes(label = round(score, 2)), vjust = -0.7, size = 3) +
scale_color_brewer(palette = "Dark2") +
labs(
title = "Sammenligning på tværs af modeller",
x = "Model",
y = "Score"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)
)
ggsave("images/2_linje_plot.png", width = 7, height = 4, dpi = 300)
# Nr. 3: Heatmap pr. model og metrik
ggplot(metrics_focus, aes(x = metric, y = wflow_id, fill = score)) +
geom_tile(color = "white") +
geom_text(aes(label = round(score, 2)), size = 3) +
scale_fill_gradient(low = "white", high = "steelblue") +
labs(
title = "Performance heatmap pr. model og metrik",
x = "Metric",
y = "Model"
) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
ggsave("images/3_heatmap_pr_model.png", width = 7, height = 4, dpi = 300)
# -------------------------------------------------------------------------
# Plot for xgboost og Random forest med de vigtigste variabler
# -------------------------------------------------------------------------
# Hent tuning-resultater for rf og xgboost
rf_result <- churn_results %>% extract_workflow_set_result("churn_recipe_rf")
xgb_result <- churn_results %>% extract_workflow_set_result("churn_recipe_xgboost")
# Hent workflow (før det er fit)
rf_workflow <- churn_results %>% extract_workflow("churn_recipe_rf")
xgb_workflow <- churn_results %>% extract_workflow("churn_recipe_xgboost")
# Vælg bedste parametre og fit modellen
best_rf <- rf_workflow %>%
finalize_workflow(select_best(rf_result, metric = "f_meas")) %>%
fit(data = churn_train)
best_xgb <- xgb_workflow %>%
finalize_workflow(select_best(xgb_result, metric = "f_meas")) %>%
fit(data = churn_train)
# Feature importance
vip_rf <- vi(extract_fit_parsnip(best_rf)) %>% mutate(model = "Random Forest")
vip_xgb <- vi(extract_fit_parsnip(best_xgb)) %>% mutate(model = "XGBoost")
# Kombinér og vis kun top 10 vigtigste variabler pr. model
vip_combined <- bind_rows(vip_rf, vip_xgb) %>%
group_by(model) %>%
slice_max(order_by = Importance, n = 10) %>%
ungroup() %>%
mutate(Variable = str_wrap(Variable, width = 25))
# Plot med labels og tekstrotation optimeret
ggplot(vip_combined, aes(x = reorder(Variable, Importance), y = Importance, fill = model)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = round(Importance, 2)), hjust = -0.1, size = 3) +
facet_wrap(~ model, scales = "free") +
coord_flip() +
labs(
title = "Top 10 vigtigste variabler pr. model",
x = "Variabel",
y = "Vigtighed"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
strip.text = element_text(size = 12, face = "bold"),
axis.text.y = element_text(size = 9)
) +
scale_y_continuous(expand = expansion(mult = c(0, 0.10))) #ektra space til labels
ggsave("images/4_top_10_variabler_pr_model.png", width = 7, height = 4, dpi = 300)
# ------------------------------------------------------------------------------
# Chunk 13
# -------------------------------------------------------
# 10. Endelig model – Finetuning af Random Forest
# -------------------------------------------------------
# undersøg kun på hele datasæt
# 1. Lav et workflow set med kun én model: Random Forest
churn_workflow_set_rf <- workflow_set(
preproc = list(churn_recipe = churn_recipe),
models  = list(rf = rf_spec)  # kun én model
)
# 2. Tænd for parallelisering
plan(multisession)
# 3. Start tidstagning
strt.time <- Sys.time()
# Chunk 14
# 4. Tuning af kun Random Forest med 25 kombinationer
churn_results_rf <- churn_workflow_set_rf |>  # <-- her var der fejl i dit input
workflow_map(
resamples = churn_folds,
grid = 25,
metrics = churn_metrics,
control = grid_ctrl,
seed = 2025
)
# Chunk 15
# 5. Tid brugt
Sys.time() - strt.time
# 6. Sluk for parallelisering
plan(sequential)
# 7. Vis bedste resultater pr. metrik
churn_results_rf |>
rank_results(select_best = TRUE) |>
select(wflow_id, .metric, mean) |>
pivot_wider(names_from = .metric, values_from = mean) |>
arrange(-f_meas)
# 8. Visualisér den bedste model
autoplot(churn_results_rf, select_best = TRUE)
# Chunk 16
# ------------------------------------------------------------------------------
# 11. Evaluering af bedste model på testdatasættet (Random Forest)
# ------------------------------------------------------------------------------
# Bemærk: Modellen i dette afsnit er baseret på finetuning med 25 kombinationer
# 1. Find bedste parametre for den bedste model
best_results <- churn_results_rf |>
extract_workflow_set_result("churn_recipe_rf") |>
select_best(metric = "f_meas")
# 2. Finaliser workflow med de fundne parametre
final_wf <- churn_results_rf |>
extract_workflow("churn_recipe_rf") |>
finalize_workflow(best_results)
# 3. Træn modellen på træningsdata og evaluer på testdata
churn_last_fit <- final_wf |>
last_fit(split = churn_split, metrics = churn_metrics)
# 4. Udskriv evalueringsmetrikker
collect_metrics(churn_last_fit)
# 5. Gem confusion matrix som objekt (brugbar til præsentation)
conf_matrix <- churn_last_fit |>
collect_predictions() |>
conf_mat(estimate = .pred_class, truth = churn)
# 6. Gem test-prædiktioner hvis ønsket
test_preds <- collect_predictions(churn_last_fit)
# 7. Træn endelig model på hele datasættet
final_model <- fit(final_wf, data = feature_engineering)
# 8. Gem modellen
saveRDS(final_model, "final_churn_model.rds")
# ------------------------------------------------------------------------------
# 11.1 Eksempel: Forudsig churn for én ny virksomhed
# ------------------------------------------------------------------------------
new_company <- tibble(
Employees = 15,
PostalCode = factor("8800"),
CompanyTypeName = factor("Aktieselskab"),
har_haft_kontakt = factor("Ja"),
deltaget_i_event = factor("Nej"),
hjælp_kategori = factor("Strategi Udvikling"),
medlem_antal_år = 2,
Branche_navn = factor("Fremstilling af maskiner og udstyr i.a.n."),
MeetingLength = 180,
PNumber = 12345678
)
# Forudsiger klassifikation og sandsynlighed
predict(final_model, new_company)                    # 0 = bliver, 1 = churn
predict(final_model, new_company, type = "prob")     # churn-sandsynlighed
# ------------------------------------------------------------------------------
# 11.2 Forudsig churn for ALLE virksomheder og tilføj resultater
# ------------------------------------------------------------------------------
# Modellen anvendes nu på hele medlemsdatabasen for at identificere churn-risiko
# Forudsiger sandsynlighed og klasse
churn_probs   <- predict(final_model, feature_engineering, type = "prob")
churn_classes <- predict(final_model, feature_engineering)
# Kombiner og omdøb kolonner
all_predictions <- bind_cols(churn_probs, churn_classes) |>
rename(
churn_prob = .pred_1,      # Sandsynlighed for churn
churn_class = .pred_class  # Klassifikation (0/1)
)
# Tilføj til datasættet og konvertér sandsynlighed til procent
full_results <- feature_engineering |>
bind_cols(all_predictions) |>
mutate(
churn_prob = round(churn_prob * 100, 1),
PNumber = pnumbers  # tilføj igen
) |>
relocate(PNumber, .before = 1)
View(feature_engineering)
# ------------------------------------------------------------------------------
# 11. Evaluering af bedste model på testdatasættet (Random Forest)
# ------------------------------------------------------------------------------
# Bemærk: Modellen i dette afsnit er baseret på finetuning med 25 kombinationer
# 1. Find bedste parametre for den bedste model
best_results <- churn_results_rf |>
extract_workflow_set_result("churn_recipe_rf") |>
select_best(metric = "f_meas")
# 2. Finaliser workflow med de fundne parametre
final_wf <- churn_results_rf |>
extract_workflow("churn_recipe_rf") |>
finalize_workflow(best_results)
# 3. Træn modellen på træningsdata og evaluer på testdata
churn_last_fit <- final_wf |>
last_fit(split = churn_split, metrics = churn_metrics)
# 4. Udskriv evalueringsmetrikker
collect_metrics(churn_last_fit)
# 5. Gem confusion matrix som objekt (brugbar til præsentation)
conf_matrix <- churn_last_fit |>
collect_predictions() |>
conf_mat(estimate = .pred_class, truth = churn)
# 6. Gem test-prædiktioner hvis ønsket
test_preds <- collect_predictions(churn_last_fit)
# 7. Træn endelig model på hele datasættet
final_model <- fit(final_wf, data = feature_engineering)
# 8. Gem modellen
saveRDS(final_model, "final_churn_model.rds")
# ------------------------------------------------------------------------------
# 11.1 Eksempel: Forudsig churn for én ny virksomhed
# ------------------------------------------------------------------------------
new_company <- tibble(
Employees = 15,
PostalCode = factor("8800"),
CompanyTypeName = factor("Aktieselskab"),
har_haft_kontakt = factor("Ja"),
deltaget_i_event = factor("Nej"),
hjælp_kategori = factor("Strategi Udvikling"),
medlem_antal_år = 2,
Branche_navn = factor("Fremstilling af maskiner og udstyr i.a.n."),
MeetingLength = 180,
PNumber = 12345678
)
# Forudsiger klassifikation og sandsynlighed
predict(final_model, new_company)                    # 0 = bliver, 1 = churn
predict(final_model, new_company, type = "prob")     # churn-sandsynlighed
# ------------------------------------------------------------------------------
# 11.2 Forudsig churn for ALLE virksomheder og tilføj resultater
# ------------------------------------------------------------------------------
# Modellen anvendes nu på hele medlemsdatabasen for at identificere churn-risiko
# Forudsiger sandsynlighed og klasse
churn_probs   <- predict(final_model, feature_engineering, type = "prob")
churn_classes <- predict(final_model, feature_engineering)
# Kombiner og omdøb kolonner
all_predictions <- bind_cols(churn_probs, churn_classes) |>
rename(
churn_prob = .pred_1,      # Sandsynlighed for churn
churn_class = .pred_class  # Klassifikation (0/1)
)
# Tilføj til datasættet og konvertér sandsynlighed til procent
full_results <- feature_engineering |>
bind_cols(all_predictions) |>
mutate(
churn_prob = round(churn_prob * 100, 1),
#PNumber = pnumbers  # tilføj igen
) |>
relocate(PNumber, .before = 1)
# ------------------------------------------------------------------------------
# 11. Evaluering af bedste model på testdatasættet (Random Forest)
# ------------------------------------------------------------------------------
# Bemærk: Modellen i dette afsnit er baseret på finetuning med 25 kombinationer
# 1. Find bedste parametre for den bedste model
best_results <- churn_results_rf |>
extract_workflow_set_result("churn_recipe_rf") |>
select_best(metric = "f_meas")
# 2. Finaliser workflow med de fundne parametre
final_wf <- churn_results_rf |>
extract_workflow("churn_recipe_rf") |>
finalize_workflow(best_results)
# 3. Træn modellen på træningsdata og evaluer på testdata
churn_last_fit <- final_wf |>
last_fit(split = churn_split, metrics = churn_metrics)
# 4. Udskriv evalueringsmetrikker
collect_metrics(churn_last_fit)
# 5. Gem confusion matrix som objekt (brugbar til præsentation)
conf_matrix <- churn_last_fit |>
collect_predictions() |>
conf_mat(estimate = .pred_class, truth = churn)
# 6. Gem test-prædiktioner hvis ønsket
test_preds <- collect_predictions(churn_last_fit)
# 7. Træn endelig model på hele datasættet
final_model <- fit(final_wf, data = feature_engineering)
# 8. Gem modellen
saveRDS(final_model, "final_churn_model.rds")
# ------------------------------------------------------------------------------
# 11.1 Eksempel: Forudsig churn for én ny virksomhed
# ------------------------------------------------------------------------------
new_company <- tibble(
Employees = 15,
PostalCode = factor("8800"),
CompanyTypeName = factor("Aktieselskab"),
har_haft_kontakt = factor("Ja"),
deltaget_i_event = factor("Nej"),
hjælp_kategori = factor("Strategi Udvikling"),
medlem_antal_år = 2,
Branche_navn = factor("Fremstilling af maskiner og udstyr i.a.n."),
MeetingLength = 180,
PNumber = 12345678
)
# Forudsiger klassifikation og sandsynlighed
predict(final_model, new_company)                    # 0 = bliver, 1 = churn
predict(final_model, new_company, type = "prob")     # churn-sandsynlighed
# ------------------------------------------------------------------------------
# 11.2 Forudsig churn for ALLE virksomheder og tilføj resultater
# ------------------------------------------------------------------------------
# Modellen anvendes nu på hele medlemsdatabasen for at identificere churn-risiko
# Forudsiger sandsynlighed og klasse
churn_probs   <- predict(final_model, feature_engineering, type = "prob")
churn_classes <- predict(final_model, feature_engineering)
# Kombiner og omdøb kolonner
all_predictions <- bind_cols(churn_probs, churn_classes) |>
rename(
churn_prob = .pred_1,      # Sandsynlighed for churn
churn_class = .pred_class  # Klassifikation (0/1)
)
# Tilføj til datasættet og konvertér sandsynlighed til procent
full_results <- feature_engineering |>
bind_cols(all_predictions) |>
mutate(
churn_prob = round(churn_prob * 100, 1),
#PNumber = pnumbers  # tilføj igen
) |>
#relocate(PNumber, .before = 1)
# Tilføj churn-risikokategorier tidligt (bruges i visualiseringer og rapporter)
full_results <- full_results |>
mutate(
churn_risiko = case_when(
churn_prob >= 80 ~ "Høj risiko",
churn_prob >= 60 ~ "Moderat risiko",
churn_prob >= 40 ~ "Lav risiko",
TRUE             ~ "Minimal risiko"
)
)
setwd("~/OneDrive - EaDania/Dataanalyse/GitHub/2_semester_opgave")
# ------------------------------------------------------------------------------
# 11. Evaluering af bedste model på testdatasættet (Random Forest)
# ------------------------------------------------------------------------------
# Bemærk: Modellen i dette afsnit er baseret på finetuning med 25 kombinationer
# 1. Find bedste parametre for den bedste model
best_results <- churn_results_rf |>
extract_workflow_set_result("churn_recipe_rf") |>
select_best(metric = "f_meas")
# 2. Finaliser workflow med de fundne parametre
final_wf <- churn_results_rf |>
extract_workflow("churn_recipe_rf") |>
finalize_workflow(best_results)
# 3. Træn modellen på træningsdata og evaluer på testdata
churn_last_fit <- final_wf |>
last_fit(split = churn_split, metrics = churn_metrics)
# 4. Udskriv evalueringsmetrikker
collect_metrics(churn_last_fit)
# 5. Gem confusion matrix som objekt (brugbar til præsentation)
conf_matrix <- churn_last_fit |>
collect_predictions() |>
conf_mat(estimate = .pred_class, truth = churn)
# 6. Gem test-prædiktioner hvis ønsket
test_preds <- collect_predictions(churn_last_fit)
# 7. Træn endelig model på hele datasættet
final_model <- fit(final_wf, data = feature_engineering)
# 8. Gem modellen
saveRDS(final_model, "final_churn_model.rds")
# ------------------------------------------------------------------------------
# 11.1 Eksempel: Forudsig churn for én ny virksomhed
# ------------------------------------------------------------------------------
new_company <- tibble(
Employees = 15,
PostalCode = factor("8800"),
CompanyTypeName = factor("Aktieselskab"),
har_haft_kontakt = factor("Ja"),
deltaget_i_event = factor("Nej"),
hjælp_kategori = factor("Strategi Udvikling"),
medlem_antal_år = 2,
Branche_navn = factor("Fremstilling af maskiner og udstyr i.a.n."),
MeetingLength = 180,
PNumber = 12345678
)
# Forudsiger klassifikation og sandsynlighed
predict(final_model, new_company)                    # 0 = bliver, 1 = churn
predict(final_model, new_company, type = "prob")     # churn-sandsynlighed
# ------------------------------------------------------------------------------
# 11.2 Forudsig churn for ALLE virksomheder og tilføj resultater
# ------------------------------------------------------------------------------
# Modellen anvendes nu på hele medlemsdatabasen for at identificere churn-risiko
# Forudsiger sandsynlighed og klasse
churn_probs   <- predict(final_model, feature_engineering, type = "prob")
churn_classes <- predict(final_model, feature_engineering)
# Kombiner og omdøb kolonner
all_predictions <- bind_cols(churn_probs, churn_classes) |>
rename(
churn_prob = .pred_1,      # Sandsynlighed for churn
churn_class = .pred_class  # Klassifikation (0/1)
)
# Tilføj til datasættet og konvertér sandsynlighed til procent
full_results <- feature_engineering |>
bind_cols(all_predictions) |>
mutate(
churn_prob = round(churn_prob * 100, 1),
#PNumber = pnumbers  # tilføj igen
) |>
#relocate(PNumber, .before = 1)
# Tilføj churn-risikokategorier tidligt (bruges i visualiseringer og rapporter)
full_results <- full_results |>
mutate(
churn_risiko = case_when(
churn_prob >= 80 ~ "Høj risiko",
churn_prob >= 60 ~ "Moderat risiko",
churn_prob >= 40 ~ "Lav risiko",
TRUE             ~ "Minimal risiko"
)
)
# Tilføj til datasættet og konvertér sandsynlighed til procent
full_results <- feature_engineering |>
bind_cols(all_predictions) |>
mutate(
churn_prob = round(churn_prob * 100, 1)
)
# Gemmer full_results som rds
saveRDS(full_results, "full_results.rds")
View(full_results)
